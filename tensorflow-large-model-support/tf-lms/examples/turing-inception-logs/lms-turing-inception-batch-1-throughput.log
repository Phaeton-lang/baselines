2022-02-20 13:38:09.555476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:38:10.032772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7
2022-02-20 13:38:10.033593: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7
2022-02-20 13:38:10.451444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2022-02-20 13:38:10.919188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.919460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:38:10.919476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:38:10.919497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:38:10.920682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:38:10.920885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:38:10.922227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:38:10.922898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:38:10.922921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:38:10.922996: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.923280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.923511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:38:10.931437: E bazel-out/k8-py2-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc:5187] (GetBFCAllocatorStats) No GPU device registered. Skipping getting stats

2022-02-20 13:38:10.931454: E bazel-out/k8-py2-opt/bin/tensorflow/python/pywrap_tensorflow_internal.cc:5388] (getPeakBytesActive) - Could not retrieve BFC Allocator Stats
2022-02-20 13:38:10.938521: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2022-02-20 13:38:10.942876: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2899885000 Hz
2022-02-20 13:38:10.943034: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c15b455920 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:38:10.943046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-02-20 13:38:10.943210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.943470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:38:10.943489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:38:10.943498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:38:10.943509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:38:10.943518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:38:10.943526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:38:10.943538: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:38:10.943546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:38:10.943582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.943865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:10.944079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:38:10.944097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:38:11.394086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-02-20 13:38:11.394126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2022-02-20 13:38:11.394147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2022-02-20 13:38:11.394272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:11.394561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:11.394817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:38:11.395154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5342 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2022-02-20 13:38:11.396207: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c17d3b2040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:38:11.396230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2022-02-20 13:38:20.673010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:38:20.822261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Train for 10 steps
Epoch 1/4
 1/10 [==>...........................] - ETA: 1:30 - loss: 2.6164 3/10 [========>.....................] - ETA: 23s - loss: 4.5342  5/10 [==============>...............] - ETA: 10s - loss: 4.1566 7/10 [====================>.........] - ETA: 4s - loss: 4.3867  9/10 [==========================>...] - ETA: 1s - loss: 4.017010/10 [==============================] - 10s 1s/step - loss: 4.2451
Epoch 2/4
 1/10 [==>...........................] - ETA: 0s - loss: 1.9590 3/10 [========>.....................] - ETA: 0s - loss: 3.5627 5/10 [==============>...............] - ETA: 0s - loss: 4.1542 7/10 [====================>.........] - ETA: 0s - loss: 4.3829 9/10 [==========================>...] - ETA: 0s - loss: 3.981710/10 [==============================] - 0s 43ms/step - loss: 3.8596
Epoch 3/4
 1/10 [==>...........................] - ETA: 0s - loss: 6.4254 3/10 [========>.....................] - ETA: 0s - loss: 3.7117 5/10 [==============>...............] - ETA: 0s - loss: 3.3001 7/10 [====================>.........] - ETA: 0s - loss: 3.6196 9/10 [==========================>...] - ETA: 0s - loss: 3.531610/10 [==============================] - 0s 42ms/step - loss: 3.4464
Epoch 4/4
 1/10 [==>...........................] - ETA: 0s - loss: 4.1102 3/10 [========>.....................] - ETA: 0s - loss: 3.8152 5/10 [==============>...............] - ETA: 0s - loss: 3.3507 7/10 [====================>.........] - ETA: 0s - loss: 3.4913 9/10 [==========================>...] - ETA: 0s - loss: 3.225610/10 [==============================] - 0s 42ms/step - loss: 3.2837
2022-02-20 13:38:25.178755: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
training throughput: 3.3967391304347827
peak active bytes(MB): 2108.9003143310547
