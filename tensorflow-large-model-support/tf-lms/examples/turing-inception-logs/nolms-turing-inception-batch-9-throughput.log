2022-02-20 13:32:28.865468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:29.344672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7
2022-02-20 13:32:29.345497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7
2022-02-20 13:32:29.763467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2022-02-20 13:32:30.230669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.230948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:32:30.230967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:30.230990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:32:30.232212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:32:30.232416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:32:30.233809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:32:30.234545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:32:30.234571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:32:30.234633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.234926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.235161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:32:30.251092: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2022-02-20 13:32:30.255529: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2899885000 Hz
2022-02-20 13:32:30.255803: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561040056930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:32:30.255818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-02-20 13:32:30.255958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.256223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:32:30.256243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:30.256253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:32:30.256264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:32:30.256287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:32:30.256295: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:32:30.256316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:32:30.256339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:32:30.256410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.256765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.257011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:32:30.257031: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:30.720247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-02-20 13:32:30.720287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2022-02-20 13:32:30.720307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2022-02-20 13:32:30.720432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.720721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.720993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:30.721244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5342 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2022-02-20 13:32:30.722487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561061cee810 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:32:30.722511: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2022-02-20 13:32:40.015876: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:32:40.248314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:32:41.289400: W tensorflow/core/common_runtime/bfc_allocator.cc:311] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Train for 10 steps
Epoch 1/4
 1/10 [==>...........................] - ETA: 1:39 - loss: 2.6547 2/10 [=====>........................] - ETA: 44s - loss: 4.3435  3/10 [========>.....................] - ETA: 26s - loss: 5.0540 4/10 [===========>..................] - ETA: 17s - loss: 5.0483 5/10 [==============>...............] - ETA: 11s - loss: 5.0503 6/10 [=================>............] - ETA: 7s - loss: 5.3314  7/10 [====================>.........] - ETA: 5s - loss: 5.1345 8/10 [=======================>......] - ETA: 2s - loss: 4.6782 9/10 [==========================>...] - ETA: 1s - loss: 4.640610/10 [==============================] - 12s 1s/step - loss: 4.5404
Epoch 2/4
 1/10 [==>...........................] - ETA: 1s - loss: 1.8818 2/10 [=====>........................] - ETA: 1s - loss: 2.0025 3/10 [========>.....................] - ETA: 0s - loss: 1.6540 4/10 [===========>..................] - ETA: 0s - loss: 1.8269 5/10 [==============>...............] - ETA: 0s - loss: 2.2530 6/10 [=================>............] - ETA: 0s - loss: 2.1551 7/10 [====================>.........] - ETA: 0s - loss: 2.1632 8/10 [=======================>......] - ETA: 0s - loss: 2.0508 9/10 [==========================>...] - ETA: 0s - loss: 2.047610/10 [==============================] - 1s 125ms/step - loss: 1.9570
Epoch 3/4
 1/10 [==>...........................] - ETA: 1s - loss: 1.8589 2/10 [=====>........................] - ETA: 0s - loss: 1.7149 3/10 [========>.....................] - ETA: 0s - loss: 1.9671 4/10 [===========>..................] - ETA: 0s - loss: 2.1139 5/10 [==============>...............] - ETA: 0s - loss: 2.1964 6/10 [=================>............] - ETA: 0s - loss: 2.3575 7/10 [====================>.........] - ETA: 0s - loss: 2.2790 8/10 [=======================>......] - ETA: 0s - loss: 2.4137 9/10 [==========================>...] - ETA: 0s - loss: 2.383110/10 [==============================] - 1s 124ms/step - loss: 2.4070
Epoch 4/4
 1/10 [==>...........................] - ETA: 1s - loss: 2.2656 2/10 [=====>........................] - ETA: 1s - loss: 1.9975 3/10 [========>.....................] - ETA: 0s - loss: 1.7436 4/10 [===========>..................] - ETA: 0s - loss: 1.8479 5/10 [==============>...............] - ETA: 0s - loss: 1.7687 6/10 [=================>............] - ETA: 0s - loss: 1.6900 7/10 [====================>.........] - ETA: 0s - loss: 1.5367 8/10 [=======================>......] - ETA: 0s - loss: 1.5855 9/10 [==========================>...] - ETA: 0s - loss: 1.598810/10 [==============================] - 1s 124ms/step - loss: 1.5629
2022-02-20 13:32:48.753314: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
training throughput: 22.5140712945591
peak active bytes(MB): 3168.32080078125
