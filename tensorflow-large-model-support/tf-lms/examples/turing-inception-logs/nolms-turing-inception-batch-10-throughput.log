2022-02-20 13:32:49.746360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:50.227326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7
2022-02-20 13:32:50.228202: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7
2022-02-20 13:32:50.646133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2022-02-20 13:32:51.115190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.115488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:32:51.115505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:51.115529: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:32:51.116840: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:32:51.117058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:32:51.118563: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:32:51.119343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:32:51.119371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:32:51.119439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.119763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.120014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:32:51.136882: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2022-02-20 13:32:51.141277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 2899885000 Hz
2022-02-20 13:32:51.141442: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a66430930 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:32:51.141454: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-02-20 13:32:51.141618: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.141886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 5.79GiB deviceMemoryBandwidth: 312.97GiB/s
2022-02-20 13:32:51.141911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:51.141923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:32:51.141936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2022-02-20 13:32:51.141944: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2022-02-20 13:32:51.141953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2022-02-20 13:32:51.141961: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2022-02-20 13:32:51.141969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:32:51.142007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.142305: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.142563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Adding visible gpu devices: 0
2022-02-20 13:32:51.142588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2022-02-20 13:32:51.603989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-02-20 13:32:51.604029: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2022-02-20 13:32:51.604034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2022-02-20 13:32:51.604169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.604468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.604743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-02-20 13:32:51.605011: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1244] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5342 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
2022-02-20 13:32:51.606328: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555a886a2510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-02-20 13:32:51.606352: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
2022-02-20 13:33:00.877455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2022-02-20 13:33:01.182695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2022-02-20 13:33:02.236442: W tensorflow/core/common_runtime/bfc_allocator.cc:311] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
Train for 10 steps
Epoch 1/4
 1/10 [==>...........................] - ETA: 1:40 - loss: 2.8577 2/10 [=====>........................] - ETA: 45s - loss: 3.4553  3/10 [========>.....................] - ETA: 26s - loss: 4.7970 4/10 [===========>..................] - ETA: 17s - loss: 5.2080 5/10 [==============>...............] - ETA: 11s - loss: 5.3711 6/10 [=================>............] - ETA: 7s - loss: 4.9016  7/10 [====================>.........] - ETA: 5s - loss: 4.5744 8/10 [=======================>......] - ETA: 3s - loss: 4.6908 9/10 [==========================>...] - ETA: 1s - loss: 4.469610/10 [==============================] - 12s 1s/step - loss: 4.2273
Epoch 2/4
 1/10 [==>...........................] - ETA: 1s - loss: 4.8000 2/10 [=====>........................] - ETA: 1s - loss: 4.1320 3/10 [========>.....................] - ETA: 0s - loss: 3.9296 4/10 [===========>..................] - ETA: 0s - loss: 3.7249 5/10 [==============>...............] - ETA: 0s - loss: 3.3023 6/10 [=================>............] - ETA: 0s - loss: 3.1319 7/10 [====================>.........] - ETA: 0s - loss: 2.9297 8/10 [=======================>......] - ETA: 0s - loss: 2.7046 9/10 [==========================>...] - ETA: 0s - loss: 2.571210/10 [==============================] - 1s 132ms/step - loss: 2.5446
Epoch 3/4
 1/10 [==>...........................] - ETA: 1s - loss: 2.6567 2/10 [=====>........................] - ETA: 1s - loss: 2.4928 3/10 [========>.....................] - ETA: 0s - loss: 1.9703 4/10 [===========>..................] - ETA: 0s - loss: 1.7274 5/10 [==============>...............] - ETA: 0s - loss: 1.6009 6/10 [=================>............] - ETA: 0s - loss: 1.5140 7/10 [====================>.........] - ETA: 0s - loss: 1.3258 8/10 [=======================>......] - ETA: 0s - loss: 1.2000 9/10 [==========================>...] - ETA: 0s - loss: 1.112710/10 [==============================] - 1s 132ms/step - loss: 1.0485
Epoch 4/4
 1/10 [==>...........................] - ETA: 1s - loss: 0.8316 2/10 [=====>........................] - ETA: 1s - loss: 0.8556 3/10 [========>.....................] - ETA: 0s - loss: 1.3174 4/10 [===========>..................] - ETA: 0s - loss: 1.7595 5/10 [==============>...............] - ETA: 0s - loss: 1.6860 6/10 [=================>............] - ETA: 0s - loss: 1.5781 7/10 [====================>.........] - ETA: 0s - loss: 1.6399 8/10 [=======================>......] - ETA: 0s - loss: 1.5755 9/10 [==========================>...] - ETA: 0s - loss: 1.737210/10 [==============================] - 1s 135ms/step - loss: 1.7282
2022-02-20 13:33:10.056453: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
training throughput: 24.360535931790498
peak active bytes(MB): 3276.35009765625
